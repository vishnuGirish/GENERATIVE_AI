{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eae49ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rgc11\\AppData\\Local\\Temp\\ipykernel_16480\\1367389293.py:26: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\rgc11\\AppData\\Local\\Temp\\ipykernel_16480\\1367389293.py:27: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 99ms/step - loss: 3.7507\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 3.6982\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 3.5172\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 3.2125\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 3.1233\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 3.0842\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 3.0607\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 3.0452\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 3.0337\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 3.0226\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 3.0153\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 102ms/step - loss: 3.0101\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 3.0116\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 3.0027\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 2.9963\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 2.9990\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 2.9931\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 2.9922\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 2.9888\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 2.9851\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 2.9817\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 2.9750\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 2.9701\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 2.9694\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 2.9697\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 2.9636\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 2.9584\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 2.9535\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 2.9486\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 2.9447\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 2.9382\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 2.9358\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 2.9319\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 2.9250\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 2.9173\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 2.9141\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 2.9141\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 2.9036\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 2.8992\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 2.8958\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 2.8924\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 2.8785\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 95ms/step - loss: 2.8868\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 2.8799\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 2.8584\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 2.8593\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 2.8494\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 2.8371\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 2.8331\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 2.8202\n",
      "The quick brown fox jumps over the                                                                                                                                                                                                        \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Load and preprocess your text data\n",
    "# You should replace this with your own dataset\n",
    "with open(\"your_text_data.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Create character-to-index and index-to-character dictionaries\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx_to_char = {idx: ch for idx, ch in enumerate(chars)}\n",
    "\n",
    "# Create training data and labels\n",
    "maxlen = 40  # Length of the input sequence\n",
    "step = 3     # Step to create overlapping sequences\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i:i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "# Vectorize the data\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_idx[char]] = 1\n",
    "    y[i, char_to_idx[next_chars[i]]] = 1\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, batch_size=128, epochs=50)\n",
    "\n",
    "# Generate text\n",
    "seed_text = \"The quick brown fox jumps over the\"\n",
    "generated_text = seed_text\n",
    "num_chars_to_generate = 200\n",
    "\n",
    "for _ in range(num_chars_to_generate):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(seed_text):\n",
    "        x_pred[0, t, char_to_idx[char]] = 1\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_char = idx_to_char[np.argmax(preds)]\n",
    "    generated_text += next_char\n",
    "    seed_text = seed_text[1:] + next_char\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac7005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910c4292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rgc11\\AppData\\Local\\Temp\\ipykernel_16480\\4286569337.py:26: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\rgc11\\AppData\\Local\\Temp\\ipykernel_16480\\4286569337.py:27: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 9s 626ms/step - loss: 3.7333\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 3.4392\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 3.1863\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 3s 560ms/step - loss: 3.1238\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 3s 588ms/step - loss: 3.0692\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 3.0647\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 3s 589ms/step - loss: 3.0587\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 3s 617ms/step - loss: 3.0423\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 3.0419\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 3s 602ms/step - loss: 3.0343\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 3.0330\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 3.0345\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 3.0394\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 3.0362\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 3.0306\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 3.0289\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 3.0257\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 3.0255\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 3.0264\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 2s 563ms/step - loss: 3.0259\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 3s 588ms/step - loss: 3.0224\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 3.0198\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 3.0185\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 3.0196\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 3s 613ms/step - loss: 3.0198\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 3.0241\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 3s 623ms/step - loss: 3.0190\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 3.0138\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 3.0258\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 3.0189\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 3.0187\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 3s 617ms/step - loss: 3.0144\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 3s 586ms/step - loss: 3.0074\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 3.0118\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 3.0099\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 3s 598ms/step - loss: 3.0081\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 3.0052\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 3s 584ms/step - loss: 2.9975\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 2.9978\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 2.9971\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 2.9968\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 2.9916\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 2.9854\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 2.9786\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 2.9870\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 2.9732\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 2.9623\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 2.9540\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 3s 598ms/step - loss: 2.9432\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 2.9348\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 2.9209\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 2s 565ms/step - loss: 2.9145\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 2.9048\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 2.8825\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 3s 592ms/step - loss: 2.8646\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 2.8466\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 2.8338\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 2.8127\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 3s 591ms/step - loss: 2.7946\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 2.7638\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 2.7434\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 3s 585ms/step - loss: 2.7174\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 2.7187\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 2.7030\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 2.6804\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 2.6608\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 2.6180\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 2.5893\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 3s 612ms/step - loss: 2.6245\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 2s 550ms/step - loss: 2.5793\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 3s 606ms/step - loss: 2.5240\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 2.4907\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 3s 595ms/step - loss: 2.4800\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 2.4455\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 3s 614ms/step - loss: 2.4163\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 2.3994\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 3s 623ms/step - loss: 2.3494\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 2.3281\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 2.3117\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 2.3045\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 3s 597ms/step - loss: 2.2845\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 3s 617ms/step - loss: 2.2847\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 2.2368\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 2s 552ms/step - loss: 2.1937\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 3s 600ms/step - loss: 2.1592\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 2.1403\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 2.1505\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 2.0803\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 2.0754\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 2s 478ms/step - loss: 2.0739\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 2.0166\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 1.9759\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 1.9378\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 1.9457\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 1.9070\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 1.9051\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 3s 588ms/step - loss: 1.8638\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 1.8370\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 1.7953\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 1.7667\n",
      "The quick brown fox jumps over the.selsslsc.tlonoe  l irrrlrgrtIehososp s i,clngse osvoa onn ail edtssefsxehfssssawp l vlahllrrrcsshssosssos o)jqn       i dcdsrlssLNuzpswssllgclnrldesse\n",
      "eeeiin n N  cdzmqNteehosnlaslglrrlcsevhswownos l\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Load and preprocess your text data\n",
    "# You should replace this with your own dataset\n",
    "with open(\"your_text_data.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Create character-to-index and index-to-character dictionaries\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx_to_char = {idx: ch for idx, ch in enumerate(chars)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create training data and labels\n",
    "maxlen = 40  # Length of the input sequence\n",
    "step = 3     # Step to create overlapping sequences\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i:i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Vectorize the data\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_idx[char]] = 1\n",
    "    y[i, char_to_idx[next_chars[i]]] = 1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, batch_size=128, epochs=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate text\n",
    "seed_text = \"The quick brown fox jumps over the\"\n",
    "generated_text = seed_text\n",
    "num_chars_to_generate = 200\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(num_chars_to_generate):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(seed_text):\n",
    "        x_pred[0, t, char_to_idx[char]] = 1\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    \n",
    "    # Use a temperature parameter for more controlled text generation\n",
    "    temperature = 0.75  # Experiment with different values\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    # Sample the next character based on the probability distribution\n",
    "    next_index = np.random.choice(len(chars), p=preds)\n",
    "    next_char = idx_to_char[next_index]\n",
    "    \n",
    "    generated_text += next_char\n",
    "    seed_text = seed_text[1:] + next_char\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1cf43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
